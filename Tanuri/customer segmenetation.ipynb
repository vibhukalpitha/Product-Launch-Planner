{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7049f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Step 0: imports & settings\n",
    "# ----------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import chi2_contingency, pointbiserialr\n",
    "\n",
    "# plotting style\n",
    "# ...existing code...\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\", font_scale=1.05)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb09110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Shape & dtypes ---\n",
      "(10000, 24)\n",
      "Product_ID               object\n",
      "Product_Name             object\n",
      "Brand                    object\n",
      "Model                    object\n",
      "Category                 object\n",
      "Market_Price            float64\n",
      "Purchase_Amount         float64\n",
      "Discount_Applied         object\n",
      "Rating                  float64\n",
      "Feedback                 object\n",
      "Customer_ID              object\n",
      "Age                       int64\n",
      "Gender                   object\n",
      "City                     object\n",
      "Purchase_Date            object\n",
      "Payment_Method           object\n",
      "Repeat_Customer          object\n",
      "Competitor_Name          object\n",
      "Competitor_Model         object\n",
      "Competitor_Price          int64\n",
      "Competitor_Rating       float64\n",
      "Promotion_Competitor     object\n",
      "Market_Share              int64\n",
      "Competitor_Feedback      object\n",
      "dtype: object\n",
      "\n",
      "--- First 5 rows ---\n",
      "  Product_ID Product_Name      Brand                          Model  \\\n",
      "0   PRD33554        Dress       Nike         Nike Tech Fleece Dress   \n",
      "1   PRD12448   Smartphone         LG                LG Note Plus 12   \n",
      "2   PRD42725   Smartwatch    Samsung                  Galaxy Watch6   \n",
      "3   PRD10823     Curtains  Whirlpool  Whirlpool Thermal Curtain Set   \n",
      "4   PRD18472      Shampoo      Nivea            Anti-Dandruff Power   \n",
      "\n",
      "      Category  Market_Price  Purchase_Amount Discount_Applied  Rating  \\\n",
      "0  Electronics        327.24           327.24               No     4.1   \n",
      "1  Electronics        236.15           189.30              Yes     4.4   \n",
      "2  Electronics        104.20            96.14              Yes     4.4   \n",
      "3  Electronics        215.56           152.10              Yes     3.4   \n",
      "4       Beauty        497.00           497.00               No     3.6   \n",
      "\n",
      "                     Feedback  ... Purchase_Date    Payment_Method  \\\n",
      "0             Packaging issue  ...    2022-11-21  Cash on Delivery   \n",
      "1  Value for money (positive)  ...    2024-01-27        Debit Card   \n",
      "2             Durable product  ...    2023-06-20        Debit Card   \n",
      "3             Heating problem  ...    2023-08-15        Debit Card   \n",
      "4               Slow delivery  ...    2022-11-03  Cash on Delivery   \n",
      "\n",
      "  Repeat_Customer   Competitor_Name  Competitor_Model Competitor_Price  \\\n",
      "0              No              Zara  Satin Slip Dress               60   \n",
      "1              No            Xiaomi     Redmi Note 12               50   \n",
      "2             Yes             Apple       Watch Ultra               70   \n",
      "3              No            Target    Room Darkening               60   \n",
      "4              No  Head & Shoulders     Classic Clean               60   \n",
      "\n",
      "  Competitor_Rating Promotion_Competitor Market_Share  Competitor_Feedback  \n",
      "0               3.4                  Yes           30         Damaged item  \n",
      "1               4.0                   No           10      Durable product  \n",
      "2               4.5                  Yes           30  Battery drains fast  \n",
      "3               3.5                   No           10  Battery drains fast  \n",
      "4               4.4                   No           30      Heating problem  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: load & quick read\n",
    "# ----------------------------\n",
    "DATA_PATH = \"/Users/tanuridinethra/Downloads/Walmart_customer_final_10000.csv\"   # <- change this to your file\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"\\n--- Shape & dtypes ---\")\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n--- First 5 rows ---\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9531823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: normalize column names & basic cleaning\n",
    "# ----------------------------\n",
    "# If column names have stray spaces or inconsistent case, normalize them:\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# Remove leading/trailing spaces in string columns (safe operation)\n",
    "for c in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# Standardize obvious binary values (e.g., Repeat_Customer, Discount_Applied)\n",
    "# If your dataset uses Yes/No variants, lowercase them to unify\n",
    "if 'Repeat_Customer' in df.columns:\n",
    "    df['Repeat_Customer'] = df['Repeat_Customer'].str.lower().replace({'yes':'yes','y':'yes','no':'no','n':'no'})\n",
    "\n",
    "if 'Discount_Applied' in df.columns:\n",
    "    df['Discount_Applied'] = df['Discount_Applied'].str.lower().replace({'yes':'yes','y':'yes','no':'no','n':'no'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33a2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: convert data types\n",
    "# ----------------------------\n",
    "# Dates\n",
    "if 'Purchase_Date' in df.columns:\n",
    "    df['Purchase_Date'] = pd.to_datetime(df['Purchase_Date'], errors='coerce')\n",
    "\n",
    "# Numeric conversions (force numeric, coerce errors -> NaN)\n",
    "num_cols = ['Market_Price', 'Purchase_Amount', 'Age', 'Competitor_Price',\n",
    "            'Competitor_Rating', 'Market_Share', 'Rating']\n",
    "num_cols = [c for c in num_cols if c in df.columns]\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "640ccacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing values (count & percent) ---\n",
      "Empty DataFrame\n",
      "Columns: [missing_count, missing_pct]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Step 4: missing values analysis\n",
    "# ----------------------------\n",
    "print(\"\\n--- Missing values (count & percent) ---\")\n",
    "missing = pd.DataFrame({\n",
    "    'missing_count': df.isna().sum(),\n",
    "    'missing_pct': df.isna().mean() * 100\n",
    "}).sort_values('missing_pct', ascending=False)\n",
    "print(missing[missing['missing_count'] > 0])\n",
    "\n",
    "# Visual missingness matrix (saves an image)\n",
    "\n",
    "plt.title(\"Missing values matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"missing_matrix.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c71d032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Numeric descriptive stats ---\n",
      "                     count        mean         std    min     25%      50%  \\\n",
      "Market_Price       10000.0  294.191455  164.624813  11.21  147.72  295.270   \n",
      "Purchase_Amount    10000.0  268.488960  154.323268   8.88  135.13  262.945   \n",
      "Age                10000.0   38.758200   12.360656  18.00   28.00   39.000   \n",
      "Competitor_Price   10000.0  108.682000  119.723165  50.00   50.00   60.000   \n",
      "Competitor_Rating  10000.0    3.850360    0.408811   2.90    3.60    3.900   \n",
      "Market_Share       10000.0   24.181600   10.357468  10.00   20.00   20.000   \n",
      "Rating             10000.0    3.980690    0.407898   2.90    3.70    4.000   \n",
      "\n",
      "                      75%     max  \n",
      "Market_Price       434.33  620.11  \n",
      "Purchase_Amount    390.50  616.77  \n",
      "Age                 49.00   60.00  \n",
      "Competitor_Price    70.00  520.00  \n",
      "Competitor_Rating    4.20    4.70  \n",
      "Market_Share        30.00   45.00  \n",
      "Rating               4.30    4.70  \n"
     ]
    }
   ],
   "source": [
    "# Step 5: numeric feature overview\n",
    "# ----------------------------\n",
    "print(\"\\n--- Numeric descriptive stats ---\")\n",
    "print(df[num_cols].describe().T)\n",
    "\n",
    "# Histograms + boxplots for each numeric feature\n",
    "for col in num_cols:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "    sns.histplot(df[col].dropna(), kde=True, ax=axes[0])\n",
    "    axes[0].set_title(f\"Distribution — {col}\")\n",
    "    sns.boxplot(x=df[col], ax=axes[1])\n",
    "    axes[1].set_title(f\"Boxplot — {col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"numeric_{col}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6691c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical columns: ['Product_ID', 'Product_Name', 'Brand', 'Model', 'Category', 'Discount_Applied', 'Feedback', 'Customer_ID', 'Gender', 'City', 'Payment_Method', 'Competitor_Name', 'Competitor_Model', 'Promotion_Competitor', 'Competitor_Feedback']\n",
      "\n",
      "--- Top values for Product_ID ---\n",
      "Product_ID\n",
      "PRD44193    8\n",
      "PRD41817    8\n",
      "PRD21309    7\n",
      "PRD33580    6\n",
      "PRD03503    6\n",
      "PRD45238    6\n",
      "PRD38416    6\n",
      "PRD45261    6\n",
      "PRD13253    6\n",
      "PRD05228    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Product_Name ---\n",
      "Product_Name\n",
      "Smartphone    687\n",
      "Face Cream    668\n",
      "Headphones    665\n",
      "Laptop        664\n",
      "Dress         646\n",
      "T-Shirt       642\n",
      "Shampoo       628\n",
      "Lamp          628\n",
      "Sofa Cover    623\n",
      "Jeans         623\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Brand ---\n",
      "Brand\n",
      "Levi's       675\n",
      "Apple        667\n",
      "LG           666\n",
      "Puma         659\n",
      "Whirlpool    652\n",
      "Dove         649\n",
      "L'Oreal      634\n",
      "Ikea         632\n",
      "Sony         623\n",
      "Samsung      614\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Model ---\n",
      "Model\n",
      "Whirlpool LED Bulb 9W         168\n",
      "Puma Classics Dress           148\n",
      "LG TONE Free FP9              110\n",
      "Levi's Denim Dress            108\n",
      "Galaxy Buds2 Pro               98\n",
      "Color Riche Shine              95\n",
      "Nike Tech Fleece Dress         93\n",
      "Sephora All Day Hydrator       91\n",
      "Men Cool Kick Deodorant        90\n",
      "Whirlpool Ceramic Cook Set     89\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Category ---\n",
      "Category\n",
      "Electronics    5617\n",
      "Beauty         2597\n",
      "Clothing       1786\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Discount_Applied ---\n",
      "Discount_Applied\n",
      "yes    5010\n",
      "no     4990\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Feedback ---\n",
      "Feedback\n",
      "Slow delivery                 1075\n",
      "Durable product               1062\n",
      "Battery drains fast           1038\n",
      "Satisfied customer            1027\n",
      "Damaged item                   992\n",
      "Usability issue                988\n",
      "Low quality                    982\n",
      "Value for money (positive)     981\n",
      "Heating problem                952\n",
      "Packaging issue                903\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Customer_ID ---\n",
      "Customer_ID\n",
      "7083a8a3-1cb4-45f4-8c02-3770ee6e1ac9    8\n",
      "5a6e1e4c-3490-40ea-9a14-bafa46390101    8\n",
      "02c72d44-841c-436d-8bd8-c0dcf85d1873    7\n",
      "64369779-86b2-4887-8d26-c2602cac0202    6\n",
      "e5077dc1-dbfa-480c-aa1e-ccc82056e600    6\n",
      "9b729a15-70d9-4a81-bb82-9b17bd1cee7b    6\n",
      "e4bc34a3-5df6-495f-8a11-b78cdc6ac3b0    6\n",
      "ee1c2572-203e-4446-a917-74bb254c5827    6\n",
      "a4b73833-9e5b-44d4-a715-4bedb1797724    6\n",
      "bbf0f424-2193-4245-bdf7-3213a77a3014    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Gender ---\n",
      "Gender\n",
      "Male      5099\n",
      "Female    4901\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for City ---\n",
      "City\n",
      "Johnfort         17\n",
      "Joshuamouth      15\n",
      "Lake Lisa        15\n",
      "Lake Michael     14\n",
      "North Michael    14\n",
      "West Ashley      13\n",
      "Lake Nicole      12\n",
      "Port David       12\n",
      "South Justin     12\n",
      "North Amy        12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Payment_Method ---\n",
      "Payment_Method\n",
      "Cash on Delivery    3355\n",
      "Debit Card          3339\n",
      "Credit Card         3306\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Competitor_Name ---\n",
      "Competitor_Name\n",
      "MarketBrand    603\n",
      "Nike           374\n",
      "Philips        320\n",
      "Levi's         283\n",
      "Xiaomi         270\n",
      "Home Centre    268\n",
      "L'Oreal        264\n",
      "Ikea           263\n",
      "Puma           234\n",
      "Adidas         226\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Competitor_Model ---\n",
      "Competitor_Model\n",
      "Perfume Pro Series    603\n",
      "Sportswear Dress      135\n",
      "Classic Clean          93\n",
      "Linen Blend Cover      93\n",
      "Smocked Dress          91\n",
      "Caesar Fry Pan         90\n",
      "Wrap Midi Dress        89\n",
      "Iso-Chill Tee          89\n",
      "Bedside Lamp 2         87\n",
      "Absolute Argan Oil     86\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Promotion_Competitor ---\n",
      "Promotion_Competitor\n",
      "No     5188\n",
      "Yes    4812\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top values for Competitor_Feedback ---\n",
      "Competitor_Feedback\n",
      "Satisfied customer            1095\n",
      "Durable product               1043\n",
      "Low quality                   1013\n",
      "Battery drains fast           1010\n",
      "Packaging issue                997\n",
      "Usability issue                994\n",
      "Damaged item                   993\n",
      "Heating problem                970\n",
      "Slow delivery                  944\n",
      "Value for money (positive)     941\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 6: categorical feature overview\n",
    "# ----------------------------\n",
    "cat_cols = [c for c in df.columns if df[c].dtype == \"object\" and c not in ['Repeat_Customer']]\n",
    "print(\"\\nCategorical columns:\", cat_cols)\n",
    "\n",
    "# Frequency tables and top categories (top 10)\n",
    "for c in cat_cols:\n",
    "    print(f\"\\n--- Top values for {c} ---\")\n",
    "    print(df[c].value_counts(dropna=False).head(10))\n",
    "\n",
    "# Plot top brands and categories if present\n",
    "if 'Brand' in df.columns:\n",
    "    top_brands = df['Brand'].value_counts().nlargest(15)\n",
    "    sns.barplot(y=top_brands.index, x=top_brands.values)\n",
    "    plt.title(\"Top 15 Brands by count\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"Brand\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"top_brands.png\")\n",
    "    plt.close()\n",
    "\n",
    "if 'Category' in df.columns:\n",
    "    top_cat = df['Category'].value_counts().nlargest(15)\n",
    "    sns.barplot(y=top_cat.index, x=top_cat.values)\n",
    "    plt.title(\"Top 15 Categories by count\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"Category\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"top_categories.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5e023b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Repeat_Customer distribution ---\n",
      "Repeat_Customer\n",
      "no     5129\n",
      "yes    4871\n",
      "Name: count, dtype: int64\n",
      "Repeat_Customer\n",
      "no     51.29\n",
      "yes    48.71\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Step 7: target variable check (Repeat_Customer)\n",
    "# ----------------------------\n",
    "if 'Repeat_Customer' in df.columns:\n",
    "    print(\"\\n--- Repeat_Customer distribution ---\")\n",
    "    print(df['Repeat_Customer'].value_counts(dropna=False))\n",
    "    print(df['Repeat_Customer'].value_counts(normalize=True, dropna=True) * 100)\n",
    "\n",
    "    # Visualize\n",
    "    sns.countplot(data=df, x='Repeat_Customer', order=df['Repeat_Customer'].value_counts().index)\n",
    "    plt.title(\"Repeat_Customer distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"repeat_customer_dist.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Create binary column for numeric correlation calculations\n",
    "    df['Repeat_Customer_bin'] = df['Repeat_Customer'].map({'yes': 1, 'no': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90bf4e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Numeric correlations ---\n",
      "                   Market_Price  Purchase_Amount       Age  Competitor_Price  \\\n",
      "Market_Price           1.000000         0.975957  0.007575          0.002409   \n",
      "Purchase_Amount        0.975957         1.000000  0.009188          0.001400   \n",
      "Age                    0.007575         0.009188  1.000000          0.010604   \n",
      "Competitor_Price       0.002409         0.001400  0.010604          1.000000   \n",
      "Competitor_Rating      0.009911         0.009298  0.023116          0.109096   \n",
      "Market_Share          -0.009588        -0.008969  0.020496          0.300571   \n",
      "Rating                 0.004709         0.006074 -0.001862          0.264644   \n",
      "\n",
      "                   Competitor_Rating  Market_Share    Rating  \n",
      "Market_Price                0.009911     -0.009588  0.004709  \n",
      "Purchase_Amount             0.009298     -0.008969  0.006074  \n",
      "Age                         0.023116      0.020496 -0.001862  \n",
      "Competitor_Price            0.109096      0.300571  0.264644  \n",
      "Competitor_Rating           1.000000      0.065481  0.136967  \n",
      "Market_Share                0.065481      1.000000  0.123594  \n",
      "Rating                      0.136967      0.123594  1.000000  \n",
      "\n",
      "--- Point-biserial correlations with Repeat_Customer ---\n",
      "Market_Price: r=0.012, p=0.241\n",
      "Purchase_Amount: r=0.014, p=0.16\n",
      "Age: r=0.001, p=0.92\n",
      "Competitor_Price: r=-0.018, p=0.0688\n",
      "Competitor_Rating: r=0.013, p=0.195\n",
      "Market_Share: r=0.026, p=0.00806\n",
      "Rating: r=0.005, p=0.611\n"
     ]
    }
   ],
   "source": [
    "# Step 8: correlation analysis (numeric & target)\n",
    "# ----------------------------\n",
    "# Numeric correlation matrix\n",
    "if len(num_cols) >= 2:\n",
    "    corr = df[num_cols].corr()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='vlag', center=0)\n",
    "    plt.title(\"Pearson correlation (numeric)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"numeric_corr.png\")\n",
    "    plt.close()\n",
    "    print(\"\\n--- Numeric correlations ---\")\n",
    "    print(corr)\n",
    "\n",
    "# Point-biserial correlation between binary Repeat_Customer and numeric features\n",
    "if 'Repeat_Customer_bin' in df.columns:\n",
    "    print(\"\\n--- Point-biserial correlations with Repeat_Customer ---\")\n",
    "    for col in num_cols:\n",
    "        mask = df['Repeat_Customer_bin'].notna() & df[col].notna()\n",
    "        if mask.sum() > 10:\n",
    "            r, p = pointbiserialr(df.loc[mask, 'Repeat_Customer_bin'], df.loc[mask, col])\n",
    "            print(f\"{col}: r={r:.3f}, p={p:.3g}\")\n",
    "        else:\n",
    "            print(f\"{col}: not enough paired data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ae10092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cramér's V: categorical vs Repeat_Customer ---\n",
      "Model                   0.180022\n",
      "Competitor_Model        0.155645\n",
      "Category                0.151387\n",
      "Competitor_Name         0.094887\n",
      "Competitor_Feedback     0.052859\n",
      "Product_Name            0.040993\n",
      "Feedback                0.030014\n",
      "Brand                   0.024449\n",
      "Discount_Applied        0.016692\n",
      "Payment_Method          0.012810\n",
      "Gender                  0.000000\n",
      "Promotion_Competitor    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 9: categorical vs Repeat_Customer (Cramér's V)\n",
    "# ----------------------------\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Compute Cramér's V statistic for categorical-categorical association.\"\"\"\n",
    "    confusion = pd.crosstab(x, y)\n",
    "    if confusion.size == 0:\n",
    "        return np.nan\n",
    "    chi2 = chi2_contingency(confusion, correction=False)[0]\n",
    "    n = confusion.sum().sum()\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion.shape\n",
    "    # bias correction\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    denom = min((kcorr-1), (rcorr-1))\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    return np.sqrt(phi2corr / denom)\n",
    "\n",
    "if 'Repeat_Customer' in df.columns:\n",
    "    print(\"\\n--- Cramér's V: categorical vs Repeat_Customer ---\")\n",
    "    cat_cols_for_cv = [c for c in cat_cols if df[c].nunique() < 200]  # limit very high-card columns\n",
    "    cramers_results = {}\n",
    "    for c in cat_cols_for_cv:\n",
    "        try:\n",
    "            v = cramers_v(df[c], df['Repeat_Customer'])\n",
    "            cramers_results[c] = v\n",
    "        except Exception as e:\n",
    "            cramers_results[c] = np.nan\n",
    "\n",
    "    cramers_df = pd.Series(cramers_results).sort_values(ascending=False)\n",
    "    print(cramers_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e76d797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Outlier summary (IQR method) ---\n",
      "Market_Price: outliers=0, lower=-282.20, upper=864.25\n",
      "Purchase_Amount: outliers=0, lower=-247.93, upper=773.56\n",
      "Age: outliers=0, lower=-3.50, upper=80.50\n",
      "Competitor_Price: outliers=1871, lower=20.00, upper=100.00\n",
      "Competitor_Rating: outliers=0, lower=2.70, upper=5.10\n",
      "Market_Share: outliers=0, lower=5.00, upper=45.00\n",
      "Rating: outliers=0, lower=2.80, upper=5.20\n"
     ]
    }
   ],
   "source": [
    "# Step 10: outlier detection (IQR method)\n",
    "# ----------------------------\n",
    "outlier_summary = []\n",
    "for c in num_cols:\n",
    "    col_series = df[c].dropna()\n",
    "    if col_series.empty:\n",
    "        continue\n",
    "    Q1 = col_series.quantile(0.25)\n",
    "    Q3 = col_series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    n_out = ((df[c] < lower) | (df[c] > upper)).sum()\n",
    "    outlier_summary.append((c, n_out, lower, upper))\n",
    "\n",
    "print(\"\\n--- Outlier summary (IQR method) ---\")\n",
    "for c, n_out, lower, upper in outlier_summary:\n",
    "    print(f\"{c}: outliers={n_out}, lower={lower:.2f}, upper={upper:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ac3f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Repeat-customer loyalty (same Brand & Category >1 times) ---\n",
      "                             Customer_ID      Brand     Category  \\\n",
      "0   0020b0f3-7120-45f6-b5c3-e037ae90d459       Nike  Electronics   \n",
      "2   0040b404-b18b-4fa6-8e94-5804f29ade39     Levi's       Beauty   \n",
      "3   005a074d-c082-445d-9307-c90a37daccaa       Puma  Electronics   \n",
      "4   0083a488-4956-4890-98f2-8e957a69c9d6    L'Oreal  Electronics   \n",
      "6   008992e4-eeeb-4515-8c8d-c59c93b5e54c         LG  Electronics   \n",
      "8   00dc7112-0b13-4442-a2d0-13238e9f8da4       Ikea       Beauty   \n",
      "10  0107bae7-246e-4908-94b3-a6d1dbf3d1fa      Apple  Electronics   \n",
      "12  01364432-f904-4901-bdfd-1df67d4de4b1       Dove     Clothing   \n",
      "13  014a0bd5-4b43-4b99-bf45-77f6041eda34         LG  Electronics   \n",
      "14  01a8ce6d-2a59-45cf-8a3f-2f852553dd3d       Nike     Clothing   \n",
      "16  01cd83fd-17c2-4743-895f-285c2c5e6e88       Ikea  Electronics   \n",
      "17  01dae9fb-dce0-4e26-b528-48904af85117  Panasonic       Beauty   \n",
      "18  01e217bc-2ec3-495f-97f0-9391fabf51b6    Samsung     Clothing   \n",
      "20  01fdc433-7313-46bd-9570-cdcdb0ed5a65       Sony  Electronics   \n",
      "21  0237b97e-3d85-4e4e-8607-64f268ddd0f4    L'Oreal       Beauty   \n",
      "23  0241794d-a116-4951-88ff-a1ff5afaa230       Nike  Electronics   \n",
      "25  02688eb8-0262-4017-ae7c-979746c19594      Nivea       Beauty   \n",
      "26  02693b63-0dfa-42c2-b271-59fb3a74fa43    Sephora       Beauty   \n",
      "29  02910205-0bea-4e7f-8a1b-94976aa624e2       Ikea  Electronics   \n",
      "30  02b41af2-63f2-465e-859a-9f0a06d2c1a7       Puma       Beauty   \n",
      "\n",
      "    purchase_count  \n",
      "0                2  \n",
      "2                2  \n",
      "3                2  \n",
      "4                2  \n",
      "6                2  \n",
      "8                2  \n",
      "10               2  \n",
      "12               3  \n",
      "13               2  \n",
      "14               2  \n",
      "16               2  \n",
      "17               3  \n",
      "18               2  \n",
      "20               3  \n",
      "21               3  \n",
      "23               2  \n",
      "25               4  \n",
      "26               4  \n",
      "29               2  \n",
      "30               3  \n",
      "\n",
      "--- Loyalty summary by Brand+Category ---\n",
      "        Brand     Category  num_unique_customers\n",
      "5       Apple  Electronics                    67\n",
      "17         LG  Electronics                    60\n",
      "47  Whirlpool  Electronics                    57\n",
      "38    Samsung  Electronics                    55\n",
      "20     Levi's  Electronics                    55\n",
      "11       Ikea  Electronics                    54\n",
      "39    Sephora       Beauty                    53\n",
      "44       Sony  Electronics                    50\n",
      "2      Adidas  Electronics                    49\n",
      "29  Panasonic  Electronics                    49\n",
      "35       Puma  Electronics                    47\n",
      "32    Philips  Electronics                    47\n",
      "12    L'Oreal       Beauty                    47\n",
      "6        Dove       Beauty                    40\n",
      "24      Nivea       Beauty                    39\n",
      "23       Nike  Electronics                    37\n",
      "1      Adidas     Clothing                    35\n",
      "26      Nivea  Electronics                    35\n",
      "8        Dove  Electronics                    33\n",
      "34       Puma     Clothing                    29\n",
      "\n",
      "--- Purchase_Amount summary by Repeat_Customer ---\n",
      "   Repeat_Customer_bin  count        mean  median         std\n",
      "0                    0   5129  266.373289  260.01  152.565457\n",
      "1                    1   4871  270.716691  267.49  156.137486\n",
      "\n",
      "--- Recommended next steps (short checklist) ---\n",
      "1) If your target is Repeat_Customer -> it's a classification problem:\n",
      "   - Handle class imbalance (SMOTE, class_weight, undersampling)\n",
      "   - Categorical encoding: target/mean encoding for high-cardinality (Brand, Model),\n",
      "     One-Hot for low-cardinality (Payment_Method, Discount_Applied)\n",
      "   - Use point-biserial/cramers results to prioritize features.\n",
      "\n",
      "2) If your target is Purchase_Amount -> regression:\n",
      "   - Log-transform highly skewed amounts before modelling\n",
      "   - Consider grouping Brand+Category into aggregated features (avg_price_by_brand, brand_market_share)\n",
      "\n",
      "3) Save cleaned dataset for modelling:\n",
      "   df.to_csv(\"cleaned_dataset_for_modeling.csv\", index=False)\n",
      "\n",
      "4) If you won't train locally and will use an API:\n",
      "   - Export a 'model-ready' CSV with proper encodings or with raw fields that the API supports.\n",
      "   - Provide a data dictionary alongside the CSV.\n",
      "\n",
      "Files saved by this script:\n",
      " - missing_matrix.png\n",
      " - numeric_*.png (per numeric column)\n",
      " - top_brands.png / top_categories.png\n",
      " - repeat_same_brand_category_details.csv\n",
      " - repeat_same_brand_category_summary.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 11: business-focused cross-tabs & the specific repeat-customer check\n",
    "# ----------------------------\n",
    "# 1) For each repeat customer, how many times they bought same Brand+Category\n",
    "if 'Repeat_Customer_bin' in df.columns:\n",
    "    repeat_df = df[df['Repeat_Customer_bin'] == 1].copy()\n",
    "    # count purchases by customer, brand, category\n",
    "    rep_group = repeat_df.groupby(['Customer_ID', 'Brand', 'Category']).size().reset_index(name='purchase_count')\n",
    "    # customers who bought same Brand+Category more than once\n",
    "    loyal_purchases = rep_group[rep_group['purchase_count'] > 1].copy()\n",
    "    print(\"\\n--- Repeat-customer loyalty (same Brand & Category >1 times) ---\")\n",
    "    print(loyal_purchases.head(20))\n",
    "    # summary: how many unique customers per brand-category\n",
    "    loyalty_summary = loyal_purchases.groupby(['Brand', 'Category'])['Customer_ID'].nunique().reset_index(name='num_unique_customers')\n",
    "    print(\"\\n--- Loyalty summary by Brand+Category ---\")\n",
    "    print(loyalty_summary.sort_values('num_unique_customers', ascending=False).head(20))\n",
    "    # Save to CSV\n",
    "    loyal_purchases.to_csv(\"repeat_same_brand_category_details.csv\", index=False)\n",
    "    loyalty_summary.to_csv(\"repeat_same_brand_category_summary.csv\", index=False)\n",
    "\n",
    "# 2) Compare purchase amounts for repeat vs non-repeat\n",
    "if 'Repeat_Customer_bin' in df.columns and 'Purchase_Amount' in df.columns:\n",
    "    summary_by_repeat = df.groupby('Repeat_Customer_bin')['Purchase_Amount'].agg(['count', 'mean', 'median', 'std']).reset_index()\n",
    "    print(\"\\n--- Purchase_Amount summary by Repeat_Customer ---\")\n",
    "    print(summary_by_repeat)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 12: recommended next steps & feature engineering hints\n",
    "# ----------------------------\n",
    "print(\"\"\"\n",
    "--- Recommended next steps (short checklist) ---\n",
    "1) If your target is Repeat_Customer -> it's a classification problem:\n",
    "   - Handle class imbalance (SMOTE, class_weight, undersampling)\n",
    "   - Categorical encoding: target/mean encoding for high-cardinality (Brand, Model),\n",
    "     One-Hot for low-cardinality (Payment_Method, Discount_Applied)\n",
    "   - Use point-biserial/cramers results to prioritize features.\n",
    "\n",
    "2) If your target is Purchase_Amount -> regression:\n",
    "   - Log-transform highly skewed amounts before modelling\n",
    "   - Consider grouping Brand+Category into aggregated features (avg_price_by_brand, brand_market_share)\n",
    "\n",
    "3) Save cleaned dataset for modelling:\n",
    "   df.to_csv(\"cleaned_dataset_for_modeling.csv\", index=False)\n",
    "\n",
    "4) If you won't train locally and will use an API:\n",
    "   - Export a 'model-ready' CSV with proper encodings or with raw fields that the API supports.\n",
    "   - Provide a data dictionary alongside the CSV.\n",
    "\n",
    "Files saved by this script:\n",
    " - missing_matrix.png\n",
    " - numeric_*.png (per numeric column)\n",
    " - top_brands.png / top_categories.png\n",
    " - repeat_same_brand_category_details.csv\n",
    " - repeat_same_brand_category_summary.csv\n",
    "\"\"\")\n",
    "\n",
    "# Save cleaned dataframe for downstream modelling\n",
    "os.makedirs(\"analysis_outputs\", exist_ok=True)\n",
    "df.to_csv(os.path.join(\"analysis_outputs\", \"cleaned_dataset_for_modeling.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1998bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discount and prediction analysis\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"/Users/tanuridinethra/Downloads/Walmart_customer_final_10000.csv\"  # <-- change to your CSV\n",
    "\n",
    "os.makedirs(\"analysis_outputs\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f5b32d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Load & basic cleaning\n",
    "# ----------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# strip spaces, normalize key fields\n",
    "for c in df.select_dtypes(include=\"object\").columns:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# types\n",
    "if \"Purchase_Date\" in df.columns:\n",
    "    df[\"Purchase_Date\"] = pd.to_datetime(df[\"Purchase_Date\"], errors=\"coerce\")\n",
    "\n",
    "num_cols = [\"Market_Price\", \"Purchase_Amount\", \"Age\", \"Competitor_Price\",\n",
    "            \"Competitor_Rating\", \"Market_Share\", \"Rating\"]\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# normalize booleans\n",
    "for c in [\"Repeat_Customer\", \"Discount_Applied\", \"Promotion_Competitor\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].str.lower().replace({\"y\":\"yes\",\"n\":\"no\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a39bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Filter to last 4 years (relative to max date in data)\n",
    "# ----------------------------\n",
    "max_date = df[\"Purchase_Date\"].max()\n",
    "if pd.isna(max_date):\n",
    "    raise ValueError(\"Purchase_Date is missing/invalid; please fix dates.\")\n",
    "\n",
    "start_date = max_date - pd.DateOffset(years=4)\n",
    "df4 = df[df[\"Purchase_Date\"] >= start_date].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "755f3f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: analysis_outputs/repeat_same_brand_category_summary.csv\n",
      "        Brand     Category  num_unique_repeat_customers\n",
      "5       Apple  Electronics                           67\n",
      "17         LG  Electronics                           60\n",
      "47  Whirlpool  Electronics                           57\n",
      "38    Samsung  Electronics                           55\n",
      "20     Levi's  Electronics                           55\n",
      "11       Ikea  Electronics                           54\n",
      "39    Sephora       Beauty                           53\n",
      "44       Sony  Electronics                           50\n",
      "2      Adidas  Electronics                           49\n",
      "29  Panasonic  Electronics                           49\n",
      "35       Puma  Electronics                           47\n",
      "32    Philips  Electronics                           47\n",
      "12    L'Oreal       Beauty                           47\n",
      "6        Dove       Beauty                           40\n",
      "24      Nivea       Beauty                           39\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Analysis: among repeat customers, who bought same Brand+Category multiple times?\n",
    "# ----------------------------\n",
    "rep = df4[df4[\"Repeat_Customer\"].str.lower() == \"yes\"].copy()\n",
    "\n",
    "# count by (Customer_ID, Brand, Category)\n",
    "repeat_counts = (\n",
    "    rep.groupby([\"Customer_ID\", \"Brand\", \"Category\"])\n",
    "      .size().reset_index(name=\"purchase_count\")\n",
    ")\n",
    "\n",
    "loyal_multi = repeat_counts[repeat_counts[\"purchase_count\"] > 1].copy()\n",
    "\n",
    "summary_brand_cat = (\n",
    "    loyal_multi.groupby([\"Brand\", \"Category\"])[\"Customer_ID\"]\n",
    "    .nunique().reset_index(name=\"num_unique_repeat_customers\")\n",
    "    .sort_values(\"num_unique_repeat_customers\", ascending=False)\n",
    ")\n",
    "\n",
    "summary_brand_cat.to_csv(\"analysis_outputs/repeat_same_brand_category_summary.csv\", index=False)\n",
    "\n",
    "print(\"Saved: analysis_outputs/repeat_same_brand_category_summary.csv\")\n",
    "print(summary_brand_cat.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f46142b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/xd0rqtps1qlfh1s45lmks7t40000gn/T/ipykernel_85401/2690488820.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = data.groupby(\"Customer_ID\", group_keys=False).apply(add_customer_signals)\n",
      "/var/folders/pk/xd0rqtps1qlfh1s45lmks7t40000gn/T/ipykernel_85401/2690488820.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = data.groupby([\"Customer_ID\",\"Category\"], group_keys=False).apply(add_cat_signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training table: analysis_outputs/loyalty_training.csv  (rows: 15334)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/xd0rqtps1qlfh1s45lmks7t40000gn/T/ipykernel_85401/2690488820.py:52: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = data.groupby([\"Customer_ID\",\"Category\",\"Brand\"], group_keys=False).apply(add_brand_cat_signals)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Build sequence labels for prediction\n",
    "# Label = 1 if NEXT purchase (same Category) keeps the SAME Brand, else 0 (switch)\n",
    "# Only consider customers who are repeat (historically) and have >=2 purchases in that Category\n",
    "# ----------------------------\n",
    "use_cols = [\n",
    "    \"Customer_ID\",\"Purchase_Date\",\"Brand\",\"Category\",\"City\",\"Gender\",\"Age\",\n",
    "    \"Discount_Applied\",\"Market_Price\",\"Purchase_Amount\",\"Competitor_Price\",\n",
    "    \"Competitor_Rating\",\"Payment_Method\",\"Market_Share\",\"Rating\",\"Repeat_Customer\"\n",
    "]\n",
    "use_cols = [c for c in use_cols if c in df4.columns]\n",
    "data = df4[use_cols].dropna(subset=[\"Customer_ID\",\"Category\",\"Brand\",\"Purchase_Date\"]).copy()\n",
    "\n",
    "# sort and create next-row info within (Customer, Category)\n",
    "data = data.sort_values([\"Customer_ID\",\"Category\",\"Purchase_Date\"])\n",
    "data[\"next_brand\"] = (\n",
    "    data.groupby([\"Customer_ID\",\"Category\"])[\"Brand\"]\n",
    "        .shift(-1)\n",
    ")\n",
    "data[\"next_date\"] = (\n",
    "    data.groupby([\"Customer_ID\",\"Category\"])[\"Purchase_Date\"]\n",
    "        .shift(-1)\n",
    ")\n",
    "\n",
    "# keep rows where a \"next\" exists\n",
    "has_next = data[~data[\"next_brand\"].isna()].copy()\n",
    "has_next[\"label_loyal\"] = (has_next[\"Brand\"] == has_next[\"next_brand\"]).astype(int)\n",
    "\n",
    "# ------------- Feature engineering (at time t, before we see t+1)\n",
    "# per-customer frequency signals up to current time\n",
    "def add_customer_signals(g):\n",
    "    g = g.sort_values(\"Purchase_Date\")\n",
    "    g[\"cust_total_so_far\"]  = np.arange(1, len(g)+1)  # 1..n\n",
    "    return g\n",
    "\n",
    "data = data.groupby(\"Customer_ID\", group_keys=False).apply(add_customer_signals)\n",
    "\n",
    "# per-customer-category frequency signals\n",
    "def add_cat_signals(g):\n",
    "    g = g.sort_values(\"Purchase_Date\")\n",
    "    g[\"cust_cat_total_so_far\"] = np.arange(1, len(g)+1)\n",
    "    return g\n",
    "\n",
    "data = data.groupby([\"Customer_ID\",\"Category\"], group_keys=False).apply(add_cat_signals)\n",
    "\n",
    "# per-customer-brand-category frequency & share\n",
    "def add_brand_cat_signals(g):\n",
    "    g = g.sort_values(\"Purchase_Date\")\n",
    "    g[\"cust_brand_cat_total_so_far\"] = np.arange(1, len(g)+1)\n",
    "    return g\n",
    "\n",
    "data = data.groupby([\"Customer_ID\",\"Category\",\"Brand\"], group_keys=False).apply(add_brand_cat_signals)\n",
    "\n",
    "# join the engineered features onto has_next (aligning by current row)\n",
    "feat_cols = [\n",
    "    \"cust_total_so_far\",\"cust_cat_total_so_far\",\"cust_brand_cat_total_so_far\"\n",
    "]\n",
    "has_next = has_next.merge(\n",
    "    data[[\"Customer_ID\",\"Category\",\"Brand\",\"Purchase_Date\"] + feat_cols],\n",
    "    on=[\"Customer_ID\",\"Category\",\"Brand\",\"Purchase_Date\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# recency: days until next purchase (can be used for survival-like targets later; keep for reference)\n",
    "has_next[\"days_to_next\"] = (has_next[\"next_date\"] - has_next[\"Purchase_Date\"]).dt.days\n",
    "\n",
    "# price/competitor gaps (optional numeric signals)\n",
    "if \"Competitor_Price\" in has_next.columns:\n",
    "    has_next[\"gap_vs_competitor\"] = has_next[\"Purchase_Amount\"] - has_next[\"Competitor_Price\"]\n",
    "if \"Market_Price\" in has_next.columns:\n",
    "    has_next[\"discount_amount\"] = has_next[\"Market_Price\"] - has_next[\"Purchase_Amount\"]\n",
    "\n",
    "# we’ll keep a compact training set:\n",
    "keep_model_cols = [\n",
    "    # label\n",
    "    \"label_loyal\",\n",
    "    # IDs/time for tracing (not used for training by AutoML unless included)\n",
    "    \"Customer_ID\",\"Purchase_Date\",\"next_date\",\n",
    "    # categorical/context\n",
    "    \"Brand\",\"Category\",\"City\",\"Gender\",\"Payment_Method\",\"Discount_Applied\",\"Repeat_Customer\",\n",
    "    # numeric\n",
    "    \"Age\",\"Market_Price\",\"Purchase_Amount\",\"Competitor_Price\",\"Competitor_Rating\",\n",
    "    \"Market_Share\",\"Rating\",\"cust_total_so_far\",\"cust_cat_total_so_far\",\"cust_brand_cat_total_so_far\",\n",
    "    \"gap_vs_competitor\",\"discount_amount\",\"days_to_next\"\n",
    "]\n",
    "keep_model_cols = [c for c in keep_model_cols if c in has_next.columns]\n",
    "\n",
    "train_df = has_next[keep_model_cols].dropna(subset=[\"label_loyal\"]).copy()\n",
    "\n",
    "# Save training table\n",
    "train_path = \"analysis_outputs/loyalty_training.csv\"\n",
    "train_df.to_csv(train_path, index=False)\n",
    "print(f\"Saved training table: {train_path}  (rows: {len(train_df)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e89c4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved inference candidates: analysis_outputs/inference_candidates.csv  (rows: 5000)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Inference candidates = last known purchase per (Customer, Category)\n",
    "# Use these rows to predict “will next be same brand?”\n",
    "# ----------------------------\n",
    "last_rows = (\n",
    "    data.sort_values(\"Purchase_Date\")\n",
    "        .groupby([\"Customer_ID\",\"Category\"], as_index=False)\n",
    "        .tail(1)\n",
    ")\n",
    "\n",
    "# align with same features\n",
    "cand = last_rows.copy()\n",
    "for col in [\"gap_vs_competitor\",\"discount_amount\"]:\n",
    "    if col not in cand.columns:\n",
    "        cand[col] = np.nan\n",
    "if \"Competitor_Price\" in cand.columns and \"Purchase_Amount\" in cand.columns:\n",
    "    cand[\"gap_vs_competitor\"] = cand[\"Purchase_Amount\"] - cand[\"Competitor_Price\"]\n",
    "if \"Market_Price\" in cand.columns and \"Purchase_Amount\" in cand.columns:\n",
    "    cand[\"discount_amount\"] = cand[\"Market_Price\"] - cand[\"Purchase_Amount\"]\n",
    "\n",
    "cand = cand[[c for c in keep_model_cols if c != \"label_loyal\" and c != \"next_date\" and c != \"days_to_next\"]]\n",
    "cand_path = \"analysis_outputs/inference_candidates.csv\"\n",
    "cand.to_csv(cand_path, index=False)\n",
    "print(f\"Saved inference candidates: {cand_path}  (rows: {len(cand)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7aff5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat Customer & Discount Analysis\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"/Users/tanuridinethra/Downloads/Walmart_customer_final_10000.csv\")\n",
    "\n",
    "# Filter repeat customers\n",
    "repeat_df = df[df['Repeat_Customer'] == 'Yes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74c23f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Customer_ID      Brand     Category  \\\n",
      "0  0020b0f3-7120-45f6-b5c3-e037ae90d459       Nike  Electronics   \n",
      "1  004011cf-4b63-4455-bd67-6ade8beb6c0a       Dove       Beauty   \n",
      "2  0040b404-b18b-4fa6-8e94-5804f29ade39     Levi's       Beauty   \n",
      "3  005a074d-c082-445d-9307-c90a37daccaa       Puma  Electronics   \n",
      "4  0083a488-4956-4890-98f2-8e957a69c9d6    L'Oreal  Electronics   \n",
      "5  008772bd-4e1b-458a-b20e-b0a5591999d6    Philips  Electronics   \n",
      "6  008992e4-eeeb-4515-8c8d-c59c93b5e54c         LG  Electronics   \n",
      "7  00bf711e-a00e-4c07-852a-0cf8520d5644  Whirlpool       Beauty   \n",
      "8  00dc7112-0b13-4442-a2d0-13238e9f8da4       Ikea       Beauty   \n",
      "9  0106c31a-e5ff-4b57-973a-54e46affc3c4       Sony  Electronics   \n",
      "\n",
      "   Purchase_Count  \n",
      "0               2  \n",
      "1               1  \n",
      "2               2  \n",
      "3               2  \n",
      "4               2  \n",
      "5               1  \n",
      "6               2  \n",
      "7               1  \n",
      "8               2  \n",
      "9               1  \n"
     ]
    }
   ],
   "source": [
    "# Count how many times a repeat customer bought the same brand/category\n",
    "repeat_analysis = (\n",
    "    repeat_df.groupby(['Customer_ID', 'Brand', 'Category'])\n",
    "    .size()\n",
    "    .reset_index(name='Purchase_Count')\n",
    "    .sort_values(['Customer_ID','Purchase_Count'], ascending=[True, False])\n",
    ")\n",
    "\n",
    "print(repeat_analysis.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0abf0c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Customer_ID      Brand     Category  \\\n",
      "0  0020b0f3-7120-45f6-b5c3-e037ae90d459       Nike  Electronics   \n",
      "1  004011cf-4b63-4455-bd67-6ade8beb6c0a       Dove       Beauty   \n",
      "2  0040b404-b18b-4fa6-8e94-5804f29ade39     Levi's       Beauty   \n",
      "3  005a074d-c082-445d-9307-c90a37daccaa       Puma  Electronics   \n",
      "4  0083a488-4956-4890-98f2-8e957a69c9d6    L'Oreal  Electronics   \n",
      "5  008772bd-4e1b-458a-b20e-b0a5591999d6    Philips  Electronics   \n",
      "6  008992e4-eeeb-4515-8c8d-c59c93b5e54c         LG  Electronics   \n",
      "7  00bf711e-a00e-4c07-852a-0cf8520d5644  Whirlpool       Beauty   \n",
      "8  00dc7112-0b13-4442-a2d0-13238e9f8da4       Ikea       Beauty   \n",
      "9  0106c31a-e5ff-4b57-973a-54e46affc3c4       Sony  Electronics   \n",
      "\n",
      "  Discount_Applied  Purchase_Count  \n",
      "0               No               2  \n",
      "1              Yes               1  \n",
      "2              Yes               2  \n",
      "3              Yes               2  \n",
      "4               No               2  \n",
      "5               No               1  \n",
      "6               No               2  \n",
      "7               No               1  \n",
      "8               No               2  \n",
      "9               No               1  \n"
     ]
    }
   ],
   "source": [
    "# Count how many repeat purchases were made with/without discount\n",
    "discount_analysis = (\n",
    "    repeat_df.groupby(['Customer_ID', 'Brand', 'Category', 'Discount_Applied'])\n",
    "    .size()\n",
    "    .reset_index(name='Purchase_Count')\n",
    ")\n",
    "\n",
    "print(discount_analysis.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4f2cc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Customer_ID    Brand     Category  Purchase_Count  \\\n",
      "0  0020b0f3-7120-45f6-b5c3-e037ae90d459     Nike  Electronics               2   \n",
      "1  004011cf-4b63-4455-bd67-6ade8beb6c0a     Dove       Beauty               1   \n",
      "2  0040b404-b18b-4fa6-8e94-5804f29ade39   Levi's       Beauty               2   \n",
      "3  005a074d-c082-445d-9307-c90a37daccaa     Puma  Electronics               2   \n",
      "4  0083a488-4956-4890-98f2-8e957a69c9d6  L'Oreal  Electronics               2   \n",
      "\n",
      "  Discount_Applied  \n",
      "0             [No]  \n",
      "1            [Yes]  \n",
      "2            [Yes]  \n",
      "3            [Yes]  \n",
      "4             [No]  \n"
     ]
    }
   ],
   "source": [
    "# Example: summarize per customer-brand-category\n",
    "api_input = discount_analysis.groupby(['Customer_ID', 'Brand', 'Category']).agg({\n",
    "    'Purchase_Count':'sum',\n",
    "    'Discount_Applied': lambda x: list(x)  # list of Yes/No\n",
    "}).reset_index()\n",
    "\n",
    "print(api_input.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d644782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_repeat(customer_id, brand, category, purchase_count, discount_history):\n",
    "    \"\"\"\n",
    "    Simulate repeat purchase prediction:\n",
    "    - If the customer ever got a discount before, predict True\n",
    "    - If the customer purchased more than 2 times, predict True\n",
    "    - Else predict False\n",
    "    \"\"\"\n",
    "    if \"Yes\" in discount_history:\n",
    "        return True\n",
    "    elif purchase_count > 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Step 5b: Apply dummy prediction\n",
    "predictions = []\n",
    "for _, row in api_input.iterrows():\n",
    "    predicted_repeat = predict_repeat(\n",
    "        row['Customer_ID'],\n",
    "        row['Brand'],\n",
    "        row['Category'],\n",
    "        row['Purchase_Count'],\n",
    "        row['Discount_Applied']\n",
    "    )\n",
    "    predictions.append({\n",
    "        \"Customer_ID\": row['Customer_ID'],\n",
    "        \"Brand\": row['Brand'],\n",
    "        \"Category\": row['Category'],\n",
    "        \"Predicted_Repeat\": predicted_repeat\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4c565a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted repeat purchase results:\n",
      "                            Customer_ID      Brand     Category  \\\n",
      "0  0020b0f3-7120-45f6-b5c3-e037ae90d459       Nike  Electronics   \n",
      "1  004011cf-4b63-4455-bd67-6ade8beb6c0a       Dove       Beauty   \n",
      "2  0040b404-b18b-4fa6-8e94-5804f29ade39     Levi's       Beauty   \n",
      "3  005a074d-c082-445d-9307-c90a37daccaa       Puma  Electronics   \n",
      "4  0083a488-4956-4890-98f2-8e957a69c9d6    L'Oreal  Electronics   \n",
      "5  008772bd-4e1b-458a-b20e-b0a5591999d6    Philips  Electronics   \n",
      "6  008992e4-eeeb-4515-8c8d-c59c93b5e54c         LG  Electronics   \n",
      "7  00bf711e-a00e-4c07-852a-0cf8520d5644  Whirlpool       Beauty   \n",
      "8  00dc7112-0b13-4442-a2d0-13238e9f8da4       Ikea       Beauty   \n",
      "9  0106c31a-e5ff-4b57-973a-54e46affc3c4       Sony  Electronics   \n",
      "\n",
      "   Predicted_Repeat  \n",
      "0             False  \n",
      "1              True  \n",
      "2              True  \n",
      "3              True  \n",
      "4             False  \n",
      "5             False  \n",
      "6             False  \n",
      "7             False  \n",
      "8             False  \n",
      "9             False  \n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create final DataFrame with predictions\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "print(\"\\nPredicted repeat purchase results:\")\n",
    "print(pred_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
